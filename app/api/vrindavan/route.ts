// app/api/vrindavan/route.ts
import { NextResponse } from "next/server";
import { GoogleGenerativeAI } from "@google/generative-ai";

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY!);
const model = genAI.getGenerativeModel({
  model: "gemini-2.5-flash-preview-09-2025",
});

// In-memory chat history (temporary â€” use DB later)
let conversationHistory: { role: "user" | "ai"; text: string }[] = [];

// Helper: format chat history for context
function formatHistory(history: { role: string; text: string }[]) {
  return history
    .map((h) => `${h.role === "user" ? "ğŸ‘¤ User" : "ğŸ¤– Vrindavan"}: ${h.text}`)
    .join("\n");
}

export async function POST(req: Request) {
  try {
    const contentType = req.headers.get("content-type") || "";
    let message = "";
    let image: File | null = null;

    // ğŸ§­ Detect request type
    if (contentType.includes("application/json")) {
      const body = await req.json();
      message = body.message;
    } else if (contentType.includes("multipart/form-data")) {
      const data = await req.formData();
      image = data.get("image") as File;
    }

    // ğŸŒ¿ IMAGE ANALYSIS
    if (image) {
      const arrayBuffer = await image.arrayBuffer();
      const buffer = Buffer.from(arrayBuffer);
      const base64Image = buffer.toString("base64");
      const mimeType = image.type;

      conversationHistory.push({
        role: "user",
        text: "ğŸ“¸ Uploaded a plant image for analysis.",
      });

      const plantPrompt = `
const plantPrompt = `
You are Vrindavan â€” a confident and friendly plant-care expert.
The user has shared a plant image. Analyze it directly and reply briefly in Markdown.

Keep it short and clear â€” just a few lines.

Include:
ğŸŒ¿ **Plant:** Name or closest match  
ğŸ’§ **Health:** Healthy / Stressed / Diseased  
âš ï¸ **Cause:** Likely reason  
ğŸŒ± **Tip:** Simple fix or care advice  
âœ… **Confidence:** Percentage of certainty (e.g., 90%)
Sound sure and caring, like you're talking to a gardener friend.
`;

      const result = await model.generateContent([
        { text: plantPrompt },
        { inlineData: { mimeType, data: base64Image } },
        { text: formatHistory(conversationHistory) },
      ]);

      const reply = result?.response?.text?.() || "âš ï¸ No analysis result.";

      conversationHistory.push({ role: "ai", text: reply });

      // keep history short
      if (conversationHistory.length > 12) {
        conversationHistory = conversationHistory.slice(-12);
      }

      // ğŸ”¥ Return both keys (for chat + analyzer)
      return NextResponse.json({ reply, result: reply });
    }

    // ğŸ’¬ TEXT CHAT
    if (message) {
      conversationHistory.push({ role: "user", text: message });

      const prompt = `
You are Vrindavan, a friendly AI botanist.
Use full chat context to answer naturally and helpfully.
Keep replies short, kind, and context-aware.
Hereâ€™s the conversation so far:
${formatHistory(conversationHistory)}
`;

      const result = await model.generateContent([{ text: prompt }]);
      const reply = result?.response?.text?.() || "ğŸ¤– No response from Vrindavan.";

      conversationHistory.push({ role: "ai", text: reply });

      // limit history
      if (conversationHistory.length > 12) {
        conversationHistory = conversationHistory.slice(-12);
      }

      return NextResponse.json({ reply, result: reply });
    }

    // ğŸª´ No input provided
    return NextResponse.json({ reply: "Please send a message or image." });
  } catch (error: any) {
    console.error("Vrindavan Error:", error);
    return NextResponse.json(
      { reply: "âŒ Error connecting to Vrindavan AI service." },
      { status: 500 }
    );
  }
}
